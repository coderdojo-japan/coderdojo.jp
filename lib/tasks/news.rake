require 'rss'
require 'net/http'
require 'json'

NEWS_YAML_PATH = 'db/news.yml'.freeze
NEWS_LOG_PATH = 'log/news.log'.freeze

namespace :news do
  desc "RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€#{NEWS_YAML_PATH} ã«ä¿å­˜"
  task fetch: :environment do
    # ãƒ­ã‚¬ãƒ¼è¨­å®šï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ï¼‹ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼‰
    console     = ActiveSupport::Logger.new(STDOUT)
    logger_file = ActiveSupport::Logger.new(NEWS_LOG_PATH)
    logger      = ActiveSupport::BroadcastLogger.new(logger_file, console)

    logger.info('==== START news:fetch ====')

    # æœ¬ç•ª/é–‹ç™ºç’°å¢ƒã§ã¯å®Ÿãƒ•ã‚£ãƒ¼ãƒ‰ã€ãã‚Œä»¥å¤–ï¼ˆãƒ†ã‚¹ãƒˆç’°å¢ƒãªã©ï¼‰ã§ã¯ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚£ãƒ¼ãƒ‰
    DOJO_NEWS_FEED = 'https://news.coderdojo.jp/feed/'
    PR_TIMES_FEED  = 'https://prtimes.jp/companyrdf.php?company_id=38935'
    TEST_NEWS_FEED = Rails.root.join('spec', 'fixtures', 'sample_news.rss')
    RSS_FEED_LIST  = (Rails.env.test? || Rails.env.staging?) ?
      [TEST_NEWS_FEED] :
      [DOJO_NEWS_FEED, PR_TIMES_FEED]

    # RSS ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ã€News ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¤‰æ›
    fetched_items = RSS_FEED_LIST.flat_map do |feed|
      feed = RSS::Parser.parse(feed, false)
      feed.items.map { |item|
        # RSS 1.0 (RDF) ã¨ RSS 2.0 ã®ä¸¡æ–¹ã«å¯¾å¿œ
        # RSS 2.0: pubDate, RSS 1.0 (RDF): dc:date
        # - PR TIMES: RSS 1.0 (RDF) å½¢å¼ - <rdf:RDF> ã‚¿ã‚°ã€dc:date ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨
        # - CoderDojo News: RSS 2.0 å½¢å¼ - <rss version="2.0"> ã‚¿ã‚°ã€pubDate ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨
        published_at = if item.respond_to?(:pubDate) && item.pubDate
                         item.pubDate
                       elsif item.respond_to?(:dc_date) && item.dc_date
                         item.dc_date
                       else
                         raise "Unexpected RSS format: neither pubDate nor dc:date found for item: #{item.link}"
                       end

        {
          'url'          => item.link,
          'title'        => item.title,
          'published_at' => published_at.iso8601  # ISO 8601 å½¢å¼ã«çµ±ä¸€
        }
      }
    end

    # å–å¾—æ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ (YAML) ã‚’èª­ã¿è¾¼ã¿ã€URL ã‚’ã‚­ãƒ¼ã¨ã—ãŸãƒãƒƒã‚·ãƒ¥ã«å¤‰æ›
    existing_items  = YAML.safe_load(File.read NEWS_YAML_PATH).index_by { it['url'] }
    existing_max_id = existing_items.flat_map { |url, item| item['id'].to_i }.max || 0

    # æ–°è¦è¨˜äº‹ã¨æ—¢å­˜è¨˜äº‹ã‚’åˆ†é›¢
    created_items = []
    updated_items = []

    fetched_items.each do |fetched_item|
      existing_item = existing_items[fetched_item['url']]

      if existing_item.nil?
        # æ–°è¦ã‚¢ã‚¤ãƒ†ãƒ ãªã‚‰ãã®ã¾ã¾è¿½åŠ 
        created_items << fetched_item
      elsif existing_item['title'] != fetched_item['title'] || existing_item['published_at'] != fetched_item['published_at']
        # ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯å…¬é–‹æ—¥ãŒå¤‰ã‚ã£ã¦ã„ãŸã‚‰æ›´æ–°
        updated_items << existing_item.merge(fetched_item)
      end
    end

    # æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ ã®ã¿ã« ID ã‚’å‰²ã‚Šå½“ã¦ï¼ˆå¤ã„é †ï¼‰
    created_items.sort_by! { Time.parse it['published_at'] }
    created_items.each.with_index(1) do |item, index|
      item['id'] = existing_max_id + index
    end

    # URL ã‚’ã‚­ãƒ¼ã«ã€æ›´æ–°ã•ã‚Œãªã‹ã£ãŸæ—¢å­˜ã® YAML ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»ä¿æŒ
    updated_urls    = updated_items.map { it['url'] }
    unchanged_items = existing_items.values.reject { updated_urls.include?(it['url']) }

    # æ–°è¦ãƒ»æ›´æ–°ãƒ»æ—¢å­˜ã®å„ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒãƒ¼ã‚¸ã—ã€æ—¥ä»˜é™é †ã§ã‚½ãƒ¼ãƒˆ
    merged_items = (unchanged_items + updated_items + created_items).sort_by {
      Time.parse(it['published_at'])
    }.reverse

    # YAML ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—
    File.open(NEWS_YAML_PATH, 'w') do |f|
      formatted_items = merged_items.map do |item|
        {
          'id'           => item['id'],
          'url'          => item['url'],
          'title'        => item['title'],
          'published_at' => item['published_at']
        }
      end

      f.write(formatted_items.to_yaml)
    end

    logger.info "âœ… Wrote #{merged_items.size} items to #{NEWS_YAML_PATH} (#{created_items.size} new, #{updated_items.size} updated)"
    logger.info "====  END news:fetch  ===="
    logger.info ""
  end

  desc "news.yml ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€ã™ã¹ã¦ã®ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å…¨è¨˜äº‹ã‚’å–å¾—"
  task 'fetch:reset' => :environment do
    # ãƒ­ã‚¬ãƒ¼è¨­å®šï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ï¼‹ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼‰
    console     = ActiveSupport::Logger.new(STDOUT)
    logger_file = ActiveSupport::Logger.new(NEWS_LOG_PATH)
    logger      = ActiveSupport::BroadcastLogger.new(logger_file, console)

    logger.info('==== START news:fetch:reset ====')

    # 1. news.yml ã‚’ç©ºã«ã™ã‚‹
    File.write(NEWS_YAML_PATH, [].to_yaml)
    logger.info("ğŸ“„ news.yml ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

    # 2. WordPress REST API ã‹ã‚‰ã™ã¹ã¦ã®æŠ•ç¨¿ã‚’å–å¾—
    dojo_news_items = fetch_all_wordpress_posts(logger)
    logger.info("ğŸ“° news.coderdojo.jp ã‹ã‚‰ #{dojo_news_items.size} ä»¶ã‚’å–å¾—")

    # 3. PR TIMES RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ã™ã¹ã¦ã®ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã‚’å–å¾—
    prtimes_items = fetch_prtimes_feed(logger)
    logger.info("ğŸ“¢ PR TIMES ã‹ã‚‰ #{prtimes_items.size} ä»¶ã‚’å–å¾—")

    # 4. ã™ã¹ã¦ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒãƒ¼ã‚¸ã—ã€ID ã‚’ä»˜ä¸
    all_items = (dojo_news_items + prtimes_items).sort_by { |item|
      Time.parse(item['published_at'])
    }

    # ID ã‚’ä»˜ä¸ï¼ˆå¤ã„é †ã§1ã‹ã‚‰ï¼‰
    all_items.each.with_index(1) do |item, index|
      item['id'] = index
    end

    # æœ€æ–°é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_items = all_items.sort_by { |item| 
      Time.parse(item['published_at'])
    }.reverse

    # 5. YAML ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—
    File.open(NEWS_YAML_PATH, 'w') do |f|
      formatted_items = sorted_items.map do |item|
        {
          'id'           => item['id'],
          'url'          => item['url'],
          'title'        => item['title'],
          'published_at' => item['published_at']
        }
      end

      f.write(formatted_items.to_yaml)
    end

    logger.info("âœ… åˆè¨ˆ #{sorted_items.size} ä»¶ã‚’ news.yml ã«ä¿å­˜ã—ã¾ã—ãŸ")
    logger.info("ğŸ“Œ æ¬¡ã¯ 'bundle exec rails news:upsert' ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åæ˜ ã—ã¦ãã ã•ã„")
    logger.info("====  END news:fetch:reset  ====")
  end

  # WordPress REST API ã‹ã‚‰ã™ã¹ã¦ã®æŠ•ç¨¿ã‚’å–å¾—
  def fetch_all_wordpress_posts(logger)
    items = []
    page = 1
    per_page = 100

    loop do
      uri = URI("https://news.coderdojo.jp/wp-json/wp/v2/posts")
      uri.query = URI.encode_www_form(page: page, per_page: per_page, status: 'publish')

      response = Net::HTTP.get_response(uri)
      break unless response.is_a?(Net::HTTPSuccess)

      posts = JSON.parse(response.body)
      break if posts.empty?

      posts.each do |post|
        items << {
          'url' => post['link'],
          'title' => post['title']['rendered'],
          'published_at' => Time.parse(post['date_gmt'] + ' UTC').iso8601
        }
      end

      logger.info("ğŸ“„ WordPress API: ãƒšãƒ¼ã‚¸ #{page} ã‹ã‚‰ #{posts.size} ä»¶å–å¾—")
      page += 1
    end

    items
  end

  # PR TIMES RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å…¨è¨˜äº‹ã‚’å–å¾—
  def fetch_prtimes_feed(logger)
    items = []

    begin
      feed = RSS::Parser.parse('https://prtimes.jp/companyrdf.php?company_id=38935', false)
      
      feed.items.each do |item|
        published_at = if item.respond_to?(:dc_date) && item.dc_date
                         item.dc_date.iso8601
                       else
                         raise "PR TIMES feed: dc:date not found for item: #{item.link}"
                       end

        items << {
          'url' => item.link,
          'title' => item.title,
          'published_at' => published_at
        }
      end

      logger.info("ğŸ“¢ PR TIMES RSS: #{items.size} ä»¶å–å¾—")
    rescue => e
      logger.error("âŒ PR TIMES ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: #{e.message}")
    end

    items
  end

  desc "#{NEWS_YAML_PATH} ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã« upsert"
  task upsert: :environment do
    console     = ActiveSupport::Logger.new(STDOUT)
    logger_file = ActiveSupport::Logger.new(NEWS_LOG_PATH)
    logger      = ActiveSupport::BroadcastLogger.new(logger_file, console)

    logger.info "==== START news:upsert ===="

    news_items = YAML.safe_load File.read(NEWS_YAML_PATH)
    created_count = 0
    updated_count = 0

    News.transaction do
      news_items.each do |item|
        news = News.find_or_initialize_by(url: item['url'])
        news.assign_attributes(
          title:        item['title'],
          published_at: item['published_at']
        )

        is_new_record = news.new_record?
        if is_new_record || news.changed?
          news.save!

          status = is_new_record ? 'new' : 'updated'
          created_count += 1 if     is_new_record
          updated_count += 1 unless is_new_record

          logger.info "[News] #{news.published_at.to_date} #{news.title} (#{status})"
        end
      end
    end

    logger.info "Upserted #{created_count + updated_count} items (#{created_count} new, #{updated_count} updated)."
    logger.info "==== END news:upsert ===="
    logger.info ""
  end
end
